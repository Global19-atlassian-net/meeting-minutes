# Alternative to stable ids

- nrc: want some interface to the compiler for tools to use
- nrc: this is vague but it's the high-level goal
- nrc: kind of tools are: dxr, IDEs, etc
- nrc: at the moment have save analysis API (not the data dumps that DXR uses)
- nrc: idea is that you use libsyntax and parse source code and you get the AST either pre- or post-expansion
- nrc: if you want type information, you use a node-id from the AST and call the save analysis APIs (`trans/save/mod`) and ask for the type of an expression node etc
- nrc: it's not really a stable API, just a first draft (if that), but basic arch. is to query based on AST node-ids
- nrc: but this approach is very constraining:
    - optimizing AST to speed up lowering and expansion is hindered
    - internally what compiler does is that it finds the AST node, reruns lowering to HIR, which means that lowering has to be reproducible, which is complex code
    - once we have HIR we can lookup in our data structures to return information about the HIR node
    - works and is kind of OK but:
		- philosophy is that the AST is interface, HIR is impl detail
		- tools don't know about HIR, but do know about AST
		- one day we would stabilize some sort of interface to the AST
		- stabilize some of the fns to parse and produce an AST
		- (or maybe "semi-stable")
- nrc: at this stage, not really bothered about details of the API, but seems good to decide if this overall arch. is correct
- nrc: eddyb's alternative was more like the HAIR approach
	- give user access to some abstracted version of the HIR, which includes type information easily accessible
- nmatsakis: would this "HAIR" thing be "desugared"?
- nrc: this is one of the fundamental issues, AST is not desugared, but I imagine that most IDE-like tools don't want desugared, though static analysis tools might want desugared stuff
- nrc: my feeling is that most tools want to work on AST and should not know about desugarings, they ought to be an impl detail
- eddyb: we may be able to hide the internals of desugaring but provide the original AST back
	- but e.g. taking the loop/match we produce for a for and actually showing it as a for might be a bit too much
	- it might work kind of like a span, where we reveal the desugaring but we give you back a span
- nmatsakis: my concern is that if we added desugarings later it would break tooling, which seems sort of like we were trying to avoid
- nmatsakis: did we conclude that using spans as the basis for queries is not a good idea?
- nrc: seems possible to make that work, but you'd need to change spans quite a lot
- nmatsakis: expand? one obvious thing is that we'd have to define our spans more precisely which is a compatibility concern
- nrc: imagine you have a macro body which expands out to a function call -- each use can resolve to different names -- so querying just on span is not enough
- nrc: the spans from post expansion have the history which should in principle be enough but...
- nrc: hard to imagine how you go from the source text to the detailed span
- nmatsakis: seems to me that macros are hard, user wants to think about use, but types are for the expansion, and it's just kind of tricky
- nrc: you can often tell a lot about uses but not macro definitions -- macro definitions don't even parse, so it's really hard to do anything sensible
- nrc: in current system, by allowing tool to have both pre- and post-expansion AST, and carrying expansion information in the spans, not a great API for tools, but there's enough for them to do anything that's possible
- nmatsakis: seems like you could expose AST but still use the span as the "persistent ID" -- the tool would extract span for (say) an expr or variable from the AST
- nrc: my intution is that spans are not precise, you will get more like "queries" and not precise "lookups"
- nrc: feels like something that should go at a higher level
- mw: you also cannot identify simple things like body of a closure that is just an expr, you would have this block of the closure -- the body would be covered by the expr, so spans in the body would be subparts of the expr, since AST nodes have overlap
- eddyb: yeah but that's the case for any subexpression
- mw: not quite, because in e.g. a binary expression, there is a distinct span for the `a + b` as a whole vs the `a` and the `b`
- mw: but there are probably cases where the same span is "implicitly upcast" into a bigger expression (paraphrased wording --ed)
- nrc: two almost orthogonal questions --
	- what nodes you are trying to identify
	- how you identify them
- nrc: and I think the "what nodes we are trying to identify" may be the more imp't question
	- do we evisage that the AST is something we want to "mess around with" and optimize in ways that would break users
	- or should the AST be a fixed interface?
	- tradeoff: it's nice to have an API that tool authors can use
	- vs can be speed and lowering by having 
- nmatsakis: can't we have it both ways by offering a "wrapped AST" API that is stable but using our own internal representation
- nrc: I think this is what eddyb meant. Question is, is that desirable? There is some runtime overhead doing these conversions, some ergonomic overhead from using methods instead of fields.
- nmatsakis: you could use normal data structures if we are going to be creating a copy when user requests it (i.e., this is not a "live mirror" into the compiler's representation)
- nrc: my feeling has been that it's not worth having two versions of the AST
- mw: sounds like we would maybe want a version of the AST optimized for doing macro expansion
- eddyb: the big idea that I had to get rid of the owned AST is:
	- map tokens to partially parsed AST subsequences
	- that get compiled into macros and larger items
	- with macro expansion, if an expression that you pass to a macro is used multiple times in that macro,
	- in each place it will have a reference back to the original token sequence
	- this way you can track exactly where (say) a `+` in the source file ends up
	- unless some syntax extension takes tokens and makes a fresh vector or something crazy
	- this way tools would have better access to the information
- nmatsakis: sounds like you would expect tools to consume this
- eddyb: only through an abstract interface like a token stream
- eddyb: way I see the AST working is that it would be consumed just by the lowering step, but would have a different interface for tools...
	- until now, way I was seeing is that we could "just" duplicate the internal parser 
	- and there is this extra info that we have and tools might want
	- if we expose it on the token streams, a crates.io libary could provide an AST overly over it
- nmatsakis: feels like one factor might be how quickly we get "de facto" lockin
- nmatsakis: it seems like we could try to design the "public interface" to give us the freedom to swich the internal represetation later, even if internally we use the same AST both for tools to consume and compiler to use
- nmatsakis: but maybe if we start building up tools on the existing AST we'll be so locked in we can't change?
- nrc: my feeling is that tools authors can deal with instability and the last thing they want is some stable API that is too abstrct to give them the info they need
- eddyb/nrc: this is different from syntax extensions -- those must be recompiled, so stability is infectious, but a tool is not like that
- nmatsakis: are you saying you would basically "compile the compiler" into the version of the plugin that you are using?
- eddyb: right, a tool author can do that, though it's a bit nasty, but it doesn't work w/ a syntax extension
- eddyb: I think we skipped over one detail --
	- when we were talking about spans: principle vs diagnostic spans
	- in a bunch of macros, where an expr is used multiple times -- or, more importantly, a span is used N times -- 
	- example, println! -- format_args!, the internal thing used by println!, what it does is matches over a tuple of arguments
	- and binds them each to a name and puts that into an array 
	- it reuses the span for a bunch of nodes
	- so if you search for the span, you'll find the expr in that tuple, but also the binding, and maybe some other things
	- the binding is going to actually have the wrong type from user's POV, it will be a reference to the type of the argument
	- this showed up in my IDE demo
	- in those cases, what we could do, is to setup the span in such a way that the expr inside the match
	- that expr shows up as being the "main" span,
	- the span owner,
	- the other places associated w/ that span are just for diagnostics
	- we want to report errors etc back to the original expr
	- but they are not actually the original expression
- nmatsakis: on a somewhat related note, it'd be nice to see the expansions at each point
- nrc: I think I may have a student interested in exactly that
- nmatsakis: \o/
- nrc: I think this difference between "the span a tool wants" (with precise history) is a different use case from "span diagnostics want"
- nrc: having those two uses separated more might be quite useful
- nmatsakis: I feel kind of good about AST being the thing that tools use, but bad about our CURRENT AST being the thing that tools use
- nmatsakis: rather than making lowering reproducible, we could just keep a map and throw it away if nobody wants it
- eddyb: instead of actually keeping ids in the AST, we could use the address
- eddyb: whatever scheme we actually end up with, we'll have some way to identify the AST (if we need it)
- eddyb: worst case, you can identify an AST node by the position it appear
- nrc: in the end though this is an impl detail, doesn't affect public APIs

